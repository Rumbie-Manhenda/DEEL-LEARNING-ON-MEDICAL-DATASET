{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d19ac92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "    horizontal-align: middle;\n",
       "}\n",
       "h1,h2 {\n",
       "    text-align: center;\n",
       "    background-color: pink;\n",
       "    padding: 20px;\n",
       "    margin: 0;\n",
       "    color: black;\n",
       "    font-family: ariel;\n",
       "   \n",
       "}\n",
       "\n",
       "h3 {\n",
       "    text-align: center;\n",
       "    border-style: solid;\n",
       "    border-width: 3px;\n",
       "    padding: 12px;\n",
       "    margin: 0;\n",
       "    color: black;\n",
       "    font-family: ariel;\n",
       "    border-radius: 80px;\n",
       "    border-color: gold;\n",
       "}\n",
       "\n",
       "body, p {\n",
       "    font-family: ariel;\n",
       "    font-size: 15px;\n",
       "    color: charcoal;\n",
       "}\n",
       "div {\n",
       "    font-size: 14px;\n",
       "    margin: 0;\n",
       "\n",
       "}\n",
       "\n",
       "h4 {\n",
       "    padding: 0px;\n",
       "    margin: 0;\n",
       "    font-family: ariel;\n",
       "    color: purple;\n",
       "    \n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "  background: #D4D4D4;\n",
       "  border-top: 1px solid gray;\n",
       "  border-bottom: 1px solid gray;\n",
       "  font-weight: normal;\n",
       "  padding-left: 2px;\n",
       "  padding-right: 2px;\n",
       "}\n",
       "blockquote {\n",
       "  background: #E6F2E6;\n",
       "  border-left: 3px solid #408040;\n",
       "  font-style: italic;\n",
       "  padding-left: 5px;\n",
       "  margin-left: 2px;\n",
       "}\n",
       "pre {\n",
       "  background: #E0F0FF;\n",
       "  border-left: 5px solid #55AAFF;\n",
       "  padding: 5px;\n",
       "  margin-left: 2px;\n",
       "}\n",
       "code {\n",
       "  background: #E0F0FF;\n",
       "  font-family: JetBrains Mono NL, Courier New, Monospaced;\n",
       "  font-size: 0.9em;\n",
       "}\n",
       "table {\n",
       "  border-spacing: 0px;\n",
       "  border-right: 1px solid gray;\n",
       "  border-bottom: 1px solid gray;\n",
       "}\n",
       "th, td {\n",
       "  border-left: 1px solid gray;\n",
       "  border-top: 1px solid gray;\n",
       "}\n",
       "th {\n",
       "  background: #D4D4D4;\n",
       "  font-weight: 600;\n",
       "}\n",
       "ul {\n",
       "  margin-left-ltr: 20px;\n",
       "  margin-right-rtl: 20px;\n",
       "}\n",
       "ol {\n",
       "  margin-left-ltr: 25px;\n",
       "  margin-right-rtl: 25px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "    horizontal-align: middle;\n",
    "}\n",
    "h1,h2 {\n",
    "    text-align: center;\n",
    "    background-color: pink;\n",
    "    padding: 20px;\n",
    "    margin: 0;\n",
    "    color: black;\n",
    "    font-family: ariel;\n",
    "   \n",
    "}\n",
    "\n",
    "h3 {\n",
    "    text-align: center;\n",
    "    border-style: solid;\n",
    "    border-width: 3px;\n",
    "    padding: 12px;\n",
    "    margin: 0;\n",
    "    color: black;\n",
    "    font-family: ariel;\n",
    "    border-radius: 80px;\n",
    "    border-color: gold;\n",
    "}\n",
    "\n",
    "body, p {\n",
    "    font-family: ariel;\n",
    "    font-size: 15px;\n",
    "    color: charcoal;\n",
    "}\n",
    "div {\n",
    "    font-size: 14px;\n",
    "    margin: 0;\n",
    "\n",
    "}\n",
    "\n",
    "h4 {\n",
    "    padding: 0px;\n",
    "    margin: 0;\n",
    "    font-family: ariel;\n",
    "    color: purple;\n",
    "    \n",
    "}\n",
    "\n",
    "h1, h2, h3, h4, h5, h6 {\n",
    "  background: #D4D4D4;\n",
    "  border-top: 1px solid gray;\n",
    "  border-bottom: 1px solid gray;\n",
    "  font-weight: normal;\n",
    "  padding-left: 2px;\n",
    "  padding-right: 2px;\n",
    "}\n",
    "blockquote {\n",
    "  background: #E6F2E6;\n",
    "  border-left: 3px solid #408040;\n",
    "  font-style: italic;\n",
    "  padding-left: 5px;\n",
    "  margin-left: 2px;\n",
    "}\n",
    "pre {\n",
    "  background: #E0F0FF;\n",
    "  border-left: 5px solid #55AAFF;\n",
    "  padding: 5px;\n",
    "  margin-left: 2px;\n",
    "}\n",
    "code {\n",
    "  background: #E0F0FF;\n",
    "  font-family: JetBrains Mono NL, Courier New, Monospaced;\n",
    "  font-size: 0.9em;\n",
    "}\n",
    "table {\n",
    "  border-spacing: 0px;\n",
    "  border-right: 1px solid gray;\n",
    "  border-bottom: 1px solid gray;\n",
    "}\n",
    "th, td {\n",
    "  border-left: 1px solid gray;\n",
    "  border-top: 1px solid gray;\n",
    "}\n",
    "th {\n",
    "  background: #D4D4D4;\n",
    "  font-weight: 600;\n",
    "}\n",
    "ul {\n",
    "  margin-left-ltr: 20px;\n",
    "  margin-right-rtl: 20px;\n",
    "}\n",
    "ol {\n",
    "  margin-left-ltr: 25px;\n",
    "  margin-right-rtl: 25px;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c6848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, utils\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, recall_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import re\n",
    "import unicodedata\n",
    "import tkinter as tk\n",
    "from tkinter import StringVar,OptionMenu, Label, Text, Entry\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        c = ['\\b|', '\\b/', '\\b-', '\\b\\\\'] \n",
    "        print(c[epoch % 4], end='')\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\b', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba12a6",
   "metadata": {},
   "source": [
    "# DISEASE PREDICTION USING SYMPTOMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8676027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = pd.read_csv('data/symptom_Description.csv')\n",
    "precautions = pd.read_csv('data/symptom_precaution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c885475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Disease   Symptom_1              Symptom_2              Symptom_3  \\\n",
      "0  Fungal infection     itching              skin_rash   nodal_skin_eruptions   \n",
      "1  Fungal infection   skin_rash   nodal_skin_eruptions    dischromic _patches   \n",
      "\n",
      "              Symptom_4 Symptom_5 Symptom_6 Symptom_7 Symptom_8 Symptom_9  \\\n",
      "0   dischromic _patches       NaN       NaN       NaN       NaN       NaN   \n",
      "1                   NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "  Symptom_10 Symptom_11 Symptom_12 Symptom_13 Symptom_14 Symptom_15  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "  Symptom_16 Symptom_17  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/dataset.csv')\n",
    "print(df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b81baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Symptom  weight\n",
      "0               itching       1\n",
      "1             skin_rash       3\n",
      "2  nodal_skin_eruptions       4\n",
      "3   continuous_sneezing       4\n",
      "4             shivering       5\n"
     ]
    }
   ],
   "source": [
    "severity = pd.read_csv('data/Symptom-severity.csv')\n",
    "print(severity.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c7d02",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4367169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Symptom_1</th>\n",
       "      <th>Symptom_2</th>\n",
       "      <th>Symptom_3</th>\n",
       "      <th>Symptom_4</th>\n",
       "      <th>Symptom_5</th>\n",
       "      <th>Symptom_6</th>\n",
       "      <th>Symptom_7</th>\n",
       "      <th>Symptom_8</th>\n",
       "      <th>Symptom_9</th>\n",
       "      <th>Symptom_10</th>\n",
       "      <th>Symptom_11</th>\n",
       "      <th>Symptom_12</th>\n",
       "      <th>Symptom_13</th>\n",
       "      <th>Symptom_14</th>\n",
       "      <th>Symptom_15</th>\n",
       "      <th>Symptom_16</th>\n",
       "      <th>Symptom_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>itching</td>\n",
       "      <td>skin_rash</td>\n",
       "      <td>nodal_skin_eruptions</td>\n",
       "      <td>dischromic _patches</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>skin_rash</td>\n",
       "      <td>nodal_skin_eruptions</td>\n",
       "      <td>dischromic _patches</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Disease  Symptom_1             Symptom_2             Symptom_3  \\\n",
       "0  Fungal infection    itching             skin_rash  nodal_skin_eruptions   \n",
       "1  Fungal infection  skin_rash  nodal_skin_eruptions   dischromic _patches   \n",
       "\n",
       "             Symptom_4 Symptom_5 Symptom_6 Symptom_7 Symptom_8 Symptom_9  \\\n",
       "0  dischromic _patches         0         0         0         0         0   \n",
       "1                    0         0         0         0         0         0   \n",
       "\n",
       "  Symptom_10 Symptom_11 Symptom_12 Symptom_13 Symptom_14 Symptom_15  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "\n",
       "  Symptom_16 Symptom_17  \n",
       "0          0          0  \n",
       "1          0          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n",
    "cols = df.columns\n",
    "data = df[cols].values.flatten()\n",
    "cols = df.columns\n",
    "\n",
    "s = pd.Series(data)\n",
    "s = s.str.strip()\n",
    "s = s.values.reshape(df.shape)\n",
    "\n",
    "df = pd.DataFrame(s, columns=df.columns)\n",
    "\n",
    "df = df.fillna(0)\n",
    "df.head()\n",
    "df = df.fillna(0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8a09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = df.values\n",
    "symptoms = severity['Symptom'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8965192d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Symptom_1</th>\n",
       "      <th>Symptom_2</th>\n",
       "      <th>Symptom_3</th>\n",
       "      <th>Symptom_4</th>\n",
       "      <th>Symptom_5</th>\n",
       "      <th>Symptom_6</th>\n",
       "      <th>Symptom_7</th>\n",
       "      <th>Symptom_8</th>\n",
       "      <th>Symptom_9</th>\n",
       "      <th>Symptom_10</th>\n",
       "      <th>Symptom_11</th>\n",
       "      <th>Symptom_12</th>\n",
       "      <th>Symptom_13</th>\n",
       "      <th>Symptom_14</th>\n",
       "      <th>Symptom_15</th>\n",
       "      <th>Symptom_16</th>\n",
       "      <th>Symptom_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "      <td>4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>vomiting</td>\n",
       "      <td>vomiting</td>\n",
       "      <td>fatigue</td>\n",
       "      <td>high_fever</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>120</td>\n",
       "      <td>822</td>\n",
       "      <td>870</td>\n",
       "      <td>726</td>\n",
       "      <td>378</td>\n",
       "      <td>1206</td>\n",
       "      <td>1986</td>\n",
       "      <td>2652</td>\n",
       "      <td>2976</td>\n",
       "      <td>3228</td>\n",
       "      <td>3408</td>\n",
       "      <td>3726</td>\n",
       "      <td>4176</td>\n",
       "      <td>4416</td>\n",
       "      <td>4614</td>\n",
       "      <td>4680</td>\n",
       "      <td>4728</td>\n",
       "      <td>4848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Disease Symptom_1 Symptom_2 Symptom_3   Symptom_4  Symptom_5  \\\n",
       "count               4920      4920      4920      4920        4920       4920   \n",
       "unique                41        34        48        54          51         39   \n",
       "top     Fungal infection  vomiting  vomiting   fatigue  high_fever          0   \n",
       "freq                 120       822       870       726         378       1206   \n",
       "\n",
       "        Symptom_6  Symptom_7  Symptom_8  Symptom_9  Symptom_10  Symptom_11  \\\n",
       "count        4920       4920       4920       4920        4920        4920   \n",
       "unique         33         27         22         23          22          19   \n",
       "top             0          0          0          0           0           0   \n",
       "freq         1986       2652       2976       3228        3408        3726   \n",
       "\n",
       "        Symptom_12  Symptom_13  Symptom_14  Symptom_15  Symptom_16  Symptom_17  \n",
       "count         4920        4920        4920        4920        4920        4920  \n",
       "unique          12           9           5           4           4           2  \n",
       "top              0           0           0           0           0           0  \n",
       "freq          4176        4416        4614        4680        4728        4848  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1552257",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_symptoms = []\n",
    "\n",
    "for disease_row in df['Disease'].index:\n",
    "    temp_list = []\n",
    "    for symptom_col in df.columns[1:]:\n",
    "        if df.loc[disease_row, symptom_col] == 0:\n",
    "            break\n",
    "        temp_list.append(df.loc[disease_row, symptom_col])\n",
    "    ordered_symptoms.append(temp_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c04f605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = sorted(df['Disease'].unique())\n",
    "descs = descriptions.sort_values(by='Disease')\n",
    "pre_c = precautions.sort_values(by='Disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16de36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patty\\AppData\\Local\\Temp\\ipykernel_10956\\1815331482.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_list.append(pre_c.iloc[i][k])\n",
      "C:\\Users\\patty\\AppData\\Local\\Temp\\ipykernel_10956\\1815331482.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if df.iloc[i][k] == 0:\n",
      "C:\\Users\\patty\\AppData\\Local\\Temp\\ipykernel_10956\\1815331482.py:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_list.append(df.iloc[i][k])\n"
     ]
    }
   ],
   "source": [
    "ordered_cautions = []\n",
    "\n",
    "for i in range(len(pre_c['Disease'])):\n",
    "    temp_list = []\n",
    "    for k in range(1,5):\n",
    "        temp_list.append(pre_c.iloc[i][k])\n",
    "    ordered_cautions.append(temp_list)\n",
    "    \n",
    "#Empty lists to append sorted values to in the symptoms data\n",
    "ordered_symptoms = []\n",
    "\n",
    "for i in range(len(df['Disease'])):\n",
    "    temp_list = []\n",
    "    for k in range(1,17):\n",
    "        if df.iloc[i][k] == 0:\n",
    "            break\n",
    "        temp_list.append(df.iloc[i][k])\n",
    "    ordered_symptoms.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0641a14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patty\\AppData\\Local\\Temp\\ipykernel_10956\\352069636.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if df.iloc[i][k] == 0 or df.iloc[i][k] in disease_dict.keys():\n",
      "C:\\Users\\patty\\AppData\\Local\\Temp\\ipykernel_10956\\352069636.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  symptoms_list.append(df.iloc[i][k])\n"
     ]
    }
   ],
   "source": [
    "disease_dict = {}\n",
    "\n",
    "for i in range(len(df['Disease'])):\n",
    "    symptoms_list = []\n",
    "    for k in range(len(df.columns)):\n",
    "        if df.iloc[i][k] == 0 or df.iloc[i][k] in disease_dict.keys():\n",
    "            continue\n",
    "        symptoms_list.append(df.iloc[i][k])\n",
    "    disease_dict[df['Disease'][i]] = symptoms_list\n",
    "    \n",
    "sorted_keys = sorted(disease_dict.keys())\n",
    "symptoms_list = []\n",
    "\n",
    "for i in range(len(sorted_keys)):\n",
    "    #Appending the list containing the symptoms from our disease dictionary\n",
    "    symptoms_list.append(disease_dict[sorted_keys[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e018924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assembling everything into a single dataframe\n",
    "df = pd.DataFrame({\"Diseases\":diseases,\"Descriptions\":descs['Description'],\n",
    "\"Precautions\":ordered_cautions, \"Symptoms\":symptoms_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3fcd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diseases</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Precautions</th>\n",
       "      <th>Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(vertigo) Paroymsal  Positional Vertigo</td>\n",
       "      <td>Benign paroxysmal positional vertigo (BPPV) is...</td>\n",
       "      <td>[lie down, avoid sudden change in body, avoid ...</td>\n",
       "      <td>[vomiting, headache, nausea, spinning_movement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AIDS</td>\n",
       "      <td>Acquired immunodeficiency syndrome (AIDS) is a...</td>\n",
       "      <td>[avoid open cuts, wear ppe if possible, consul...</td>\n",
       "      <td>[muscle_wasting, patches_in_throat, high_fever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Acne</td>\n",
       "      <td>Acne vulgaris is the formation of comedones, p...</td>\n",
       "      <td>[bath twice, avoid fatty spicy food, drink ple...</td>\n",
       "      <td>[skin_rash, pus_filled_pimples, blackheads, sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Alcoholic hepatitis</td>\n",
       "      <td>Alcoholic hepatitis is a diseased, inflammator...</td>\n",
       "      <td>[stop alcohol consumption, consult doctor, med...</td>\n",
       "      <td>[vomiting, yellowish_skin, abdominal_pain, swe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allergy</td>\n",
       "      <td>An allergy is an immune system response to a f...</td>\n",
       "      <td>[apply calamine, cover area with bandage, nan,...</td>\n",
       "      <td>[continuous_sneezing, shivering, chills, water...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Diseases  \\\n",
       "9   (vertigo) Paroymsal  Positional Vertigo   \n",
       "23                                     AIDS   \n",
       "11                                     Acne   \n",
       "31                      Alcoholic hepatitis   \n",
       "2                                   Allergy   \n",
       "\n",
       "                                         Descriptions  \\\n",
       "9   Benign paroxysmal positional vertigo (BPPV) is...   \n",
       "23  Acquired immunodeficiency syndrome (AIDS) is a...   \n",
       "11  Acne vulgaris is the formation of comedones, p...   \n",
       "31  Alcoholic hepatitis is a diseased, inflammator...   \n",
       "2   An allergy is an immune system response to a f...   \n",
       "\n",
       "                                          Precautions  \\\n",
       "9   [lie down, avoid sudden change in body, avoid ...   \n",
       "23  [avoid open cuts, wear ppe if possible, consul...   \n",
       "11  [bath twice, avoid fatty spicy food, drink ple...   \n",
       "31  [stop alcohol consumption, consult doctor, med...   \n",
       "2   [apply calamine, cover area with bandage, nan,...   \n",
       "\n",
       "                                             Symptoms  \n",
       "9   [vomiting, headache, nausea, spinning_movement...  \n",
       "23  [muscle_wasting, patches_in_throat, high_fever...  \n",
       "11  [skin_rash, pus_filled_pimples, blackheads, sc...  \n",
       "31  [vomiting, yellowish_skin, abdominal_pain, swe...  \n",
       "2   [continuous_sneezing, shivering, chills, water...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5932e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "medicines = pd.read_csv('testingData/disease_medicines.csv')\n",
    "riskfactors = pd.read_csv('testingData/disease_riskFactors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3da4fada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Medicine_Name</th>\n",
       "      <th>Risk_Factors</th>\n",
       "      <th>Precautions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADHD</td>\n",
       "      <td>[no medicine available (consult doctor)]</td>\n",
       "      <td>[Exposure to environmental toxins, family hist...</td>\n",
       "      <td>[protein-rich breakfast, walk to school if pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acne</td>\n",
       "      <td>[Isoniazid (antibiotics)]</td>\n",
       "      <td>[Being teenager, Hormonal changes, Friction or...</td>\n",
       "      <td>[Bath twice, avoid fatty spicy food, drink ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adenomyosis</td>\n",
       "      <td>[no medicine available (consult doctor)]</td>\n",
       "      <td>[Prior uterine surgery, such as a C-section or...</td>\n",
       "      <td>[No precaution]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alzheimer's</td>\n",
       "      <td>[cholinesterase inhibitors]</td>\n",
       "      <td>[Lack of exercise, Obesity, Smoking, High BP, ...</td>\n",
       "      <td>[Stopping smoking, keeping alcohol to a minimu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amnesia</td>\n",
       "      <td>[no medicine available (consult doctor)]</td>\n",
       "      <td>[Brain surgery, head injury or trauma, Stroke,...</td>\n",
       "      <td>[Avoid heavy use of alcohol, drugs, Stay menta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Disease                             Medicine_Name  \\\n",
       "0         ADHD  [no medicine available (consult doctor)]   \n",
       "1         Acne                 [Isoniazid (antibiotics)]   \n",
       "2  Adenomyosis  [no medicine available (consult doctor)]   \n",
       "3  Alzheimer's               [cholinesterase inhibitors]   \n",
       "4      Amnesia  [no medicine available (consult doctor)]   \n",
       "\n",
       "                                        Risk_Factors  \\\n",
       "0  [Exposure to environmental toxins, family hist...   \n",
       "1  [Being teenager, Hormonal changes, Friction or...   \n",
       "2  [Prior uterine surgery, such as a C-section or...   \n",
       "3  [Lack of exercise, Obesity, Smoking, High BP, ...   \n",
       "4  [Brain surgery, head injury or trauma, Stroke,...   \n",
       "\n",
       "                                         Precautions  \n",
       "0  [protein-rich breakfast, walk to school if pos...  \n",
       "1  [Bath twice, avoid fatty spicy food, drink ple...  \n",
       "2                                    [No precaution]  \n",
       "3  [Stopping smoking, keeping alcohol to a minimu...  \n",
       "4  [Avoid heavy use of alcohol, drugs, Stay menta...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(medicines, riskfactors, left_on = 'Disease_ID', right_on= 'DID', how = 'inner')\n",
    "\n",
    "data = data[['Medicine_Name', 'DNAME', 'RISKFAC', 'PRECAU']]\n",
    "def list_agg(series):\n",
    "    return list(series)\n",
    "# Group by 'DNAME' (disease name) and aggregate 'Medicine_Name' and 'RISKFAC' into lists\n",
    "new_data = data.groupby('DNAME').agg({\n",
    "    'Medicine_Name': list_agg,\n",
    "    'RISKFAC': list_agg,\n",
    "    'PRECAU':list_agg\n",
    "}).reset_index()\n",
    "new_data.columns = ['Disease', 'Medicine_Name', 'Risk_Factors', 'Precautions']\n",
    "\n",
    "new_data = pd.DataFrame( new_data, columns=new_data.columns)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26086d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Disease']= new_data['Disease'].str.lower()\n",
    "new_data['Disease']= new_data['Disease'].str.replace(r'[^\\w\\s]', '')\n",
    "\n",
    "df['Diseases']= df['Diseases'].str.lower()\n",
    "df['Diseases']= df['Diseases'].str.replace(r'[^\\w\\s\\']', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d334549f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been exported to Disease_data\\disease_data.csv\n"
     ]
    }
   ],
   "source": [
    "data = pd.merge(new_data, df, left_on= 'Disease', right_on= 'Diseases', how = 'left')\n",
    "data.drop(columns = ['Diseases', \"Precautions_y\"], inplace = True )\n",
    "nan_description = \"No Description found for this disease\"\n",
    "nan_symptom = \"No Symptoms found for this disease\"\n",
    "\n",
    "data['Descriptions'].fillna(nan_description, inplace=True)\n",
    "data['Symptoms'].fillna(nan_symptom, inplace = True)\n",
    "data.head()\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory = 'Disease_data'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Specify the file path\n",
    "file_path = os.path.join(directory, 'disease_data.csv')\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Write DataFrame to CSV\n",
    "data.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame has been exported to {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3984b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18550d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model= pd.read_csv('data/dataset.csv')\n",
    "symptoms_data2 = df_model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93fed683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Symptom_1</th>\n",
       "      <th>Symptom_2</th>\n",
       "      <th>Symptom_3</th>\n",
       "      <th>Symptom_4</th>\n",
       "      <th>Symptom_5</th>\n",
       "      <th>Symptom_6</th>\n",
       "      <th>Symptom_7</th>\n",
       "      <th>Symptom_8</th>\n",
       "      <th>Symptom_9</th>\n",
       "      <th>Symptom_10</th>\n",
       "      <th>Symptom_11</th>\n",
       "      <th>Symptom_12</th>\n",
       "      <th>Symptom_13</th>\n",
       "      <th>Symptom_14</th>\n",
       "      <th>Symptom_15</th>\n",
       "      <th>Symptom_16</th>\n",
       "      <th>Symptom_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Disease  Symptom_1  Symptom_2  Symptom_3  Symptom_4  Symptom_5  \\\n",
       "0  Fungal infection          1          3          4          0          0   \n",
       "1  Fungal infection          3          4          0          0          0   \n",
       "2  Fungal infection          1          4          0          0          0   \n",
       "3  Fungal infection          1          3          0          0          0   \n",
       "4  Fungal infection          1          3          4          0          0   \n",
       "\n",
       "   Symptom_6  Symptom_7  Symptom_8  Symptom_9  Symptom_10  Symptom_11  \\\n",
       "0          0          0          0          0           0           0   \n",
       "1          0          0          0          0           0           0   \n",
       "2          0          0          0          0           0           0   \n",
       "3          0          0          0          0           0           0   \n",
       "4          0          0          0          0           0           0   \n",
       "\n",
       "   Symptom_12  Symptom_13  Symptom_14  Symptom_15  Symptom_16  Symptom_17  \n",
       "0           0           0           0           0           0           0  \n",
       "1           0           0           0           0           0           0  \n",
       "2           0           0           0           0           0           0  \n",
       "3           0           0           0           0           0           0  \n",
       "4           0           0           0           0           0           0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.isna().sum()\n",
    "cols = df_model.columns\n",
    "data = df_model[cols].values.flatten()\n",
    "cols = df_model.columns\n",
    "\n",
    "s = pd.Series(data)\n",
    "s = s.str.strip()\n",
    "s = s.values.reshape(df_model.shape)\n",
    "\n",
    "df_model = pd.DataFrame(s, columns=df_model.columns)\n",
    "\n",
    "df_model = df_model.fillna(0)\n",
    "df_model.head()\n",
    "df_model = df_model.fillna(0)\n",
    "df_model.head(2)\n",
    "\n",
    "vals = df_model.values\n",
    "symptoms = severity['Symptom'].unique()\n",
    "#encode the symptoms with their severity weight\n",
    "len(symptoms)# 132 unique symptoms\n",
    "for i in range(len(symptoms)):\n",
    "    vals[vals == symptoms[i]] = severity[severity['Symptom'] == symptoms[i]]['weight'].values[0]\n",
    "d = pd.DataFrame(vals, columns=cols)\n",
    "\n",
    "d = d.replace('dischromic _patches', 0)\n",
    "d = d.replace('spotting_ urination',0)\n",
    "symptoms_data= d.replace('foul_smell_of urine',0)\n",
    "symptoms_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72a4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd82b2f4",
   "metadata": {},
   "source": [
    "### EXPLORATORY DATA ANALYSIS\n",
    "\n",
    "We countplot to visualise the frequency distribution of the symptoms to understand the distribution of symptoms across all diseases. It helps identify common symptoms that may occur across multiple diseases and less common symptoms that may be more specific to certain diseases.Symptoms with a weight of 0 are ignored as they do not provide meaningful information about disease manifestation. Symptoms with higher weights are indicative of their greater importance in diagnosing specific diseases.\n",
    "\n",
    "From the distribution below, it's notable that symptom 4 emerges as the most prevalent across all diseases, indicating its widespread occurrence and potential relevance in various medical conditions. Conversely, symptoms with weights 1 and 7 appear to be least common, possibly suggesting their rarity or specificity to certain diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bedc782",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = symptoms_data['Disease']\n",
    "features = symptoms_data.drop(columns= ['Disease'])\n",
    "\n",
    "class_counts = labels.value_counts()\n",
    "\n",
    "group1 = class_counts[:len(class_counts)//2]\n",
    "group2 = class_counts[len(class_counts)//2:]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=group1.index, y=group1.values)\n",
    "plt.title('Class Distribution (Group 1)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=group2.index, y=group2.values)\n",
    "plt.title('Class Distribution (Group 2)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db930c2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=symptoms_data.melt(id_vars=['Disease'], value_vars=symptoms_data.columns[1:]), x='value')\n",
    "plt.title('Frequency Distribution of Symptoms')\n",
    "plt.xlabel('Symptom')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ca9a9",
   "metadata": {},
   "source": [
    "Correlation analysis helps identify if certain symptoms tend to occur together. Understanding symptom correlations can assist in providing insights into potential underlying relationships between symptoms and diseases, thus aiding in explaining som decisions made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083cf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "corr_matrix = symptoms_data.iloc[:, 1:].corr()\n",
    "\n",
    "# Heatmap to visualize correlation between symptoms\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Between Symptoms')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11da300",
   "metadata": {},
   "source": [
    "Understanding the distribution of diseases in the dataset is crucial for assessing class imbalance. It helps ensure that the dataset is adequately representative of all diseases and can guide model evaluation and selection of appropriate evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot to visualize frequency distribution of diseases\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=symptoms_data, x='Disease')\n",
    "plt.title('Frequency Distribution of Diseases')\n",
    "plt.xlabel('Disease')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eff962",
   "metadata": {},
   "source": [
    "##  Why is this a multiclass multilabel classification problem ?\n",
    " \n",
    "1. **Multiclass Classification**: The model's task is to classify instances (patients) into one of multiple disease classes. In this case, there are multiple diseases that could be predicted based on the given symptoms. For example, given a set of symptoms, the model might predict \"Fungal Infection\" and \"GERD\" as the two most likely diseases.\n",
    "\n",
    "2. **Multilabel Classification**: Each instance (patient) can belong to multiple classes (diseases) simultaneously. In this scenario, it's possible for a patient to exhibit symptoms that are indicative of more than one disease. For instance, a patient might have symptoms that correspond to both \"Fungal Infection\" and \"Food Allergy\".\n",
    "\n",
    "Therefore, with the task of predicting the two most likely diseases from a set of given symptoms, the problem is a multiclass multilabel classification problem. The model needs to learn the relationships between symptoms and diseases to make accurate predictions about which diseases are most likely given the observed symptoms.\n",
    "\n",
    "\n",
    "### FIRST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model2 = pd.read_csv('testingData/Training.csv')\n",
    "df_model2.drop(columns=['Unnamed: 133'], inplace=True)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "labels = df_model2['prognosis']\n",
    "col_labels = labels.unique()\n",
    "features = df_model2.iloc[:, :-1]\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)\n",
    "print(\"Shape of features:\", features.shape)\n",
    "\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels = to_categorical(labels_encoded)\n",
    "features = np.reshape(features, (features.shape[0], -1))\n",
    "print(\"Shape of reshaped features: \", features.shape)\n",
    "print(\"Shape of reshaped labels: \", labels.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025be006",
   "metadata": {},
   "source": [
    "\n",
    "### SECOND DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dde889",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms_data = symptoms_data.copy()\n",
    "#move the first column symptoms_data['Disease'] to be the last column\n",
    "disease_column = symptoms_data.pop('Disease')\n",
    "label_encoder = LabelEncoder()\n",
    "# Reinsert the 'Disease' column at the end\n",
    "symptoms_data['Disease'] = disease_column\n",
    "\n",
    "\n",
    "features = symptoms_data.iloc[:, :-1]\n",
    "labels = symptoms_data['Disease']\n",
    "col_labels = labels.unique()\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)\n",
    "print(\"Shape of features:\", features.shape)\n",
    "\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels = to_categorical(labels_encoded)\n",
    "print(\"Shape of reshaped labels: \", labels.shape)\n",
    "features = np.reshape(features, (features.shape[0], -1))\n",
    "print(\"Shape of reshaped features: \", features.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07eca3c",
   "metadata": {},
   "source": [
    "### MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb3f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_model(optimizer='adam', dropout_rate=0.3, num_layers=2, units_per_layer=64):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(units_per_layer, activation='relu', input_shape=(features.shape[1],)))\n",
    "    for _ in range(num_layers - 1):  # Add additional hidden layers if num_layers > 1\n",
    "        model.add(layers.Dense(units_per_layer, activation='tanh', kernel_regularizer=tf.keras.regularizers.l1(0.002)))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(labels.shape[1], activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy' ,keras.metrics.Recall(),keras.metrics.Precision()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e71a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dffe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = create_model()\n",
    "network.fit(X_train,y_train,epochs = 30, batch_size= 32,verbose=0,callbacks=[CustomCallback()])\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss, accuracy, precision, recall_metric = network.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test Precision:\", precision)\n",
    "print(\"Test Recall (Keras metric):\", recall_metric)\n",
    "\n",
    "\n",
    "y_pred = network.predict(X_test)\n",
    "y_pred_array = np.argmax(y_pred_raw,axis=1)\n",
    "y_pred_labels = np.reshape(y_pred_array, (y_pred_array.shape[0], -1))\n",
    "y_pred_one_hot = to_categorical(y_pred_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050731b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert one-hot encoded y_test into 1D array\n",
    "y_test_indices = y_test.argmax(axis=1)\n",
    "y_pred_binary = y_pred_one_hot.argmax(axis=1)\n",
    "conf_matrix = confusion_matrix(y_test_indices, y_pred_binary)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d',cmap='Blues', xticklabels=col_labels, yticklabels=col_labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc74a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "initial_weights = model.get_weights()\n",
    "K = 4\n",
    "num_val_samples = len(X_train) // K\n",
    "num_epochs = 20\n",
    "all_recall_histories = []\n",
    "\n",
    "for i in range(K):\n",
    "    print('processing fold', i)\n",
    "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
    "    val_data = X_train[a:b]\n",
    "    val_targets = y_train[a:b]\n",
    "    \n",
    "\n",
    "    partial_train_data = np.concatenate([X_train[:a], X_train[b:]], axis=0)\n",
    "    partial_train_targets = np.concatenate([y_train[:a], y_train[b:]], axis=0)\n",
    "\n",
    "    # Reset model weights before training each fold\n",
    "    model.set_weights(initial_weights)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=32, verbose=0,callbacks=[CustomCallback()])\n",
    "\n",
    "    recall_history = history.history['accuracy']\n",
    "    all_recall_histories.append(recall_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afd243",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_recall_history = [np.mean([x[i] for x in all_recall_histories])for i in range(num_epochs)]\n",
    "plt.plot(range(1, len(average_recall_history) + 1), average_recall_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "hist.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75210e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model accuracy\n",
    "plt.plot(hist['accuracy'])\n",
    "plt.plot(hist['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Losss\n",
    "plt.plot(hist['loss'])\n",
    "plt.plot(hist['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classification report using predictions for categorical model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "categorical_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print('Results for Categorical Model')\n",
    "print(accuracy_score(y_test, y_pred_one_hot))\n",
    "print(classification_report(y_test, y_pred_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a62a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ee5ad8c",
   "metadata": {},
   "source": [
    "# BASELINE MODEL :MACHINE  LEARNING\n",
    "### Multinomial Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea01f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_df= pd.read_csv('trainingData/symptom-disease-train-dataset.csv')\n",
    "# Split data into features and labels\n",
    "features = clf_df['text']\n",
    "labels = clf_df['label']\n",
    "clf_df.head()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=420)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the MNB classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "# Predictions MLB\n",
    "y_pred_nb = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "# Predictions MLB\n",
    "y_pred_svm= svm.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "# Classification report\n",
    "#print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226015a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the MNB classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "# Predictions MLB\n",
    "y_pred_nb = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "# Predictions MLB\n",
    "y_pred_svm= svm.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "# Classification report\n",
    "#print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the classifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# Calculate metrics for Naive Bayes\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "nb_precision = precision_score(y_test, y_pred_nb, average='weighted')\n",
    "nb_recall = recall_score(y_test, y_pred_nb, average='weighted')\n",
    "nb_f1 = f1_score(y_test, y_pred_nb, average='weighted')\n",
    "\n",
    "# Calculate metrics for SVM\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "svm_precision = precision_score(y_test, y_pred_svm, average='weighted')\n",
    "svm_recall = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "svm_f1 = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "results_df = pd.DataFrame({\n",
    "    'Algorithm': ['Multinomial Naive Bayes', 'Support Vector Machine (SVM)'],\n",
    "    'Accuracy': [nb_accuracy, svm_accuracy],\n",
    "    'Precision': [nb_precision, svm_precision],\n",
    "    'Recall': [nb_recall, svm_recall],\n",
    "    'F1-score': [nb_f1, svm_f1]\n",
    "})\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6945c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\patty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\patty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\patty\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd5a9958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "migraine headache . ca n't sleep . whole body shaking shivering . feel dizzy sometimes .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>308</td>\n",
       "      <td>migraine headache . ca n't sleep . whole body ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>asthma get wheezing breathing problem . also f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>798</td>\n",
       "      <td>Signs symptom primary ovarian insufficiency si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>cough , high_fever , breathlessness , family_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>596</td>\n",
       "      <td>chill , vomiting , high_fever , sweating , hea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                       cleaned_text\n",
       "0    308  migraine headache . ca n't sleep . whole body ...\n",
       "1     35  asthma get wheezing breathing problem . also f...\n",
       "2    798  Signs symptom primary ovarian insufficiency si...\n",
       "3    149  cough , high_fever , breathlessness , family_h...\n",
       "4    596  chill , vomiting , high_fever , sweating , hea..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('trainingData/symptom-disease-train-dataset.csv')\n",
    "\n",
    "# Initialize WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    \n",
    "     # Stem tokens\n",
    "    #stemmed_tokens = [stemmer.stem(word) for word in lemmatized_tokens]\n",
    "    \n",
    "    # Join tokens back into text\n",
    "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply preprocessing to the 'text' column\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "# Print the cleaned text\n",
    "print(df['cleaned_text'].iloc[0])\n",
    "df.drop(columns=['text'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231e5d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of features:  100\n",
      "first label of the dataset 866\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Features and labels\n",
    "features =df['cleaned_text']\n",
    "labels = df['label']\n",
    "\n",
    "\n",
    "\n",
    "# Tokenization\n",
    "max_words = 10000  # Maximum number of words to tokenize\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_words)\n",
    "features= features.tolist()\n",
    "tokenizer.fit_on_texts(features)\n",
    "sequences = tokenizer.texts_to_sequences(features)\n",
    "\n",
    "# Padding\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_len = 100  # Maximum sequence length\n",
    "\n",
    "\n",
    "features = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_len)\n",
    "print(\"Length of features: \",len(features[1]))\n",
    "\n",
    "# Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "labels_encoded = labels_encoded.reshape((labels.shape[0],1))\n",
    "labels_onehot= encoder.fit_transform(labels_encoded)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_onehot, test_size=0.2, random_state=42)\n",
    "# Number of unique classes for output layer\n",
    "num_classes = len(label_encoder.classes_)\n",
    "#print(\"X_train\",X_train[1])\n",
    "#print(\"x_train for example word: \",feature)\n",
    "print(\"first label of the dataset\",labels_onehot.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d751d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "example_text = \"I have been having migraines and headaches. I can't sleep. My whole body is shaking and shivering. I feel dizzy sometimes.\"\n",
    "tokenizer.fit_on_texts(example_text)\n",
    "sequence = tokenizer.texts_to_sequences(example_text)\n",
    "feature = keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_len)\n",
    "\n",
    "print(\"x_train for example word: \",feature)\n",
    "\n",
    "\n",
    "\n",
    "#DECODE THE PREDICTED OUTPUT\n",
    "\n",
    "labels_encoded = labels_onehot.reshape(-1, labels_onehot.shape[1])\n",
    "\n",
    "# Inverse transform one-hot encoded labels\n",
    "labels_encoded_inverse = encoder.inverse_transform(labels_encoded)\n",
    "\n",
    "# Inverse transform label encoding\n",
    "labels_decoded = label_encoder.inverse_transform(labels_encoded_inverse)\n",
    "\n",
    "# Print the decoded label for the first sample\n",
    "print(labels_decoded[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=max_len))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "               metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe2218",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=max_len))\n",
    "model3.add(layers.GlobalMaxPool1D())\n",
    "model3.add(layers.Dense(64, activation='relu'))\n",
    "model3.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "model3.summary()\n",
    "\n",
    "history = model3.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=64)\n",
    "loss3, accuracy3, precision3, recall3 = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Loss:\", loss3)\n",
    "print(\"Test Accuracy:\", accuracy3)\n",
    "print(\"Test Precision:\", precision3)\n",
    "print(\"Test Recall (Keras metric):\", recall3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b27f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38478cc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26868\\3516718034.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mexample_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_prediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "example_text = \"having migraines and headaches. I can't sleep.  shaking and shivering. dizzy .\"\n",
    "tokenizer.fit_on_texts(example_text)\n",
    "sequence = tokenizer.texts_to_sequences(example_text)\n",
    "feature = keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_len)\n",
    "\n",
    "\n",
    "example_prediction = model.predict(feature)\n",
    "print(example_prediction)\n",
    "\n",
    "#decode the prediction\n",
    "labels_encoded = example_prediction.reshape(-1, labels_onehot.shape[1])\n",
    "\n",
    "# Inverse transform one-hot encoded labels\n",
    "labels_encoded_inverse = encoder.inverse_transform(labels_encoded)\n",
    "\n",
    "# Inverse transform label encoding\n",
    "labels_decoded = label_encoder.inverse_transform(labels_encoded_inverse)\n",
    "\n",
    "# Print the decoded label for the first sample\n",
    "print(labels_decoded[0])\n",
    "\n",
    "index_237 = df[df['label'] == 394].index\n",
    "df['cleaned_text'].iloc[index_237]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "def create_model(optimizer='adam', dropout_rate=0.3, num_layers=2, units_per_layer=128):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(units_per_layer, activation='relu', input_shape=(max_len,)))\n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(layers.Dense(units_per_layer, activation='tanh', kernel_regularizer=tf.keras.regularizers.l1(0.002)))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dea2229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               12928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 866)               111714    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141154 (551.38 KB)\n",
      "Trainable params: 141154 (551.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "network_FNN = create_model()\n",
    "network_FNN.fit(X_train,y_train,epochs = 30, batch_size= 64,verbose=0,callbacks=[CustomCallback()])\n",
    "network_FNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f33e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 3.2764 - accuracy: 0.6877 - recall: 0.6442 - precision: 0.9758\n",
      "Test Loss: 3.2763755321502686\n",
      "Test Accuracy: 0.6876663565635681\n",
      "Test Precision: 0.6441881060600281\n",
      "Test Recall (Keras metric): 0.975806474685669\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[4.6381343e-02 1.2698401e-05 7.7875275e-06 ... 7.2490649e-05\n",
      "  1.5786033e-04 3.9775255e-06]\n",
      " [2.5944884e-05 1.3674504e-06 2.3945158e-06 ... 4.1473149e-06\n",
      "  2.4086883e-06 1.4218813e-06]]\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall_metric = network_FNN.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test Precision:\", precision)\n",
    "print(\"Test Recall (Keras metric):\", recall_metric)\n",
    "predictions =  network_FNN.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d48ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "example_text = \"having migraines and headaches. I can't sleep.  shaking and shivering. dizzy .\"\n",
    "tokenizer.fit_on_texts(example_text)\n",
    "sequence = tokenizer.texts_to_sequences(example_text)\n",
    "feature = keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_len)\n",
    "\n",
    "example_prediction = model.predict(feature)\n",
    "print(example_prediction)\n",
    "\n",
    "#decode the prediction\n",
    "labels_encoded = example_prediction.reshape(-1, labels_onehot.shape[1])\n",
    "\n",
    "# Inverse transform one-hot encoded labels\n",
    "labels_encoded_inverse = encoder.inverse_transform(labels_encoded)\n",
    "\n",
    "# Inverse transform label encoding\n",
    "labels_decoded = label_encoder.inverse_transform(labels_encoded_inverse)\n",
    "\n",
    "# Print the decoded label for the first sample\n",
    "print(labels_decoded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbdfecd",
   "metadata": {},
   "source": [
    "### WORD EMBEDDINGS: GLOBAL VECTORS FOR WORD REPRESENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7064dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  \n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath, encoding = 'utf-8') as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('trainingData/glove.6B/glove.6B.50d.txt', tokenizer.word_index, embedding_dim )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#94% of the vocabulary is covered by the pretrained model, which is a good coverage of our vocabulary.\n",
    "nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))\n",
    "nonzero_elements / vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc7eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, \n",
    "                           embedding_dim, \n",
    "                           input_length=max_len,\n",
    "                          trainable= True))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(128, activation='tanh'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef21a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=64)\n",
    "loss, accuracy, precision, recall_metric = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test Precision:\", precision)\n",
    "print(\"Test Recall (Keras metric):\", recall_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae54616",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_text = \" migraines and headaches. I can't sleep.  shaking and shivering. dizzy .\"\n",
    "tokenizer.fit_on_texts(example_text)\n",
    "sequence = tokenizer.texts_to_sequences(example_text)\n",
    "feature = keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_len)\n",
    "\n",
    "\n",
    "example_prediction = model.predict(feature)\n",
    "print(example_prediction)\n",
    "\n",
    "#decode the prediction\n",
    "labels_encoded = example_prediction.reshape(-1, labels_onehot.shape[1])\n",
    "\n",
    "# Inverse transform one-hot encoded labels\n",
    "labels_encoded_inverse = encoder.inverse_transform(labels_encoded)\n",
    "\n",
    "# Inverse transform label encoding\n",
    "labels_decoded = label_encoder.inverse_transform(labels_encoded_inverse)\n",
    "\n",
    "# Print the decoded label for the first sample\n",
    "print(labels_decoded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05873a33",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9818fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(layers.Conv1D(256,5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(128, activation='tanh'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9358943",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=64)\n",
    "loss, accuracy, precision, recall_metric = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test Precision:\", precision)\n",
    "print(\"Test Recall (Keras metric):\", recall_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7806e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "example_text = \"I have been having migraines and headaches. I can't sleep. My whole body is shaking and shivering. I feel dizzy sometimes.\"\n",
    "tokenizer.fit_on_texts(example_text)\n",
    "sequence = tokenizer.texts_to_sequences(example_text)\n",
    "feature = keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_len)\n",
    "\n",
    "\n",
    "\n",
    "example_prediction = model.predict(feature)\n",
    "print(example_prediction)\n",
    "\n",
    "#decode the prediction\n",
    "labels_encoded = example_prediction.reshape(-1, labels_onehot.shape[1])\n",
    "\n",
    "# Inverse transform one-hot encoded labels\n",
    "labels_encoded_inverse = encoder.inverse_transform(labels_encoded)\n",
    "\n",
    "# Inverse transform label encoding\n",
    "labels_decoded = label_encoder.inverse_transform(labels_encoded_inverse)\n",
    "\n",
    "# Print the decoded label for the first sample\n",
    "print(labels_decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64fb8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(layers.Conv1D(256, 5, activation='relu'))  # Changed filter size to 5\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dropout(0.5))  # Added dropout for regularization\n",
    "model.add(layers.Dense(128, activation='tanh'))\n",
    "model.add(layers.Dropout(0.5))  # Added dropout for regularization\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),  # Added learning rate scheduling\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=20,  # Increased epochs for more training\n",
    "                    batch_size=64,  # Changed batch size\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[EarlyStopping(patience=3)])  # Early stopping to prevent overfitting\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy, recall, precision = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test Recall:\", recall)\n",
    "print(\"Test Precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f0e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"migraine headache . ca n't sleep . whole body shaking shivering . feel dizzy sometimes .\"\n",
    "tokenizer.fit_on_texts(example_text)\n",
    "sequence = tokenizer.texts_to_sequences(example_text)\n",
    "feature = keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_len)\n",
    "\n",
    "\n",
    "example_prediction = model.predict(feature)\n",
    "print(example_prediction)\n",
    "\n",
    "#decode the prediction\n",
    "labels_encoded = example_prediction.reshape(-1, labels_onehot.shape[1])\n",
    "\n",
    "# Inverse transform one-hot encoded labels\n",
    "labels_encoded_inverse = encoder.inverse_transform(labels_encoded)\n",
    "\n",
    "# Inverse transform label encoding\n",
    "labels_decoded = label_encoder.inverse_transform(labels_encoded_inverse)\n",
    "\n",
    "# Print the decoded label for the first sample\n",
    "print(labels_decoded[0])\n",
    "filtered_df = df[df['label'] == 284]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940da351",
   "metadata": {},
   "source": [
    "## LSTM-based recurrent neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "embedding_dim = 50  # Set the dimension of word embeddings\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len),\n",
    "   layers.LSTM(units=128),\n",
    "    layers.Dense(units=64, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "#early_stopping = EarlyStopping(monitor='val_oss', patience=3)\n",
    "\n",
    "num_classes# 866\n",
    "X_train.shape#(4507, 100)\n",
    "y_test.shape #(1127, 866)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827fe181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy, precision, recall_metric = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test Precision:\", precision)\n",
    "print(\"Test Recall (Keras metric):\", recall_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d412390",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"migraines and headaches. can't sleep.  body shaking and shivering. dizzy sometimes.\"\n",
    "tokenizer.fit_on_texts(example_text)\n",
    "sequence = tokenizer.texts_to_sequences(example_text)\n",
    "feature = keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_len)\n",
    "\n",
    "prediction = model.predict(feature)\n",
    "\n",
    "# Reshape example_prediction to a 2D array\n",
    "\n",
    "\n",
    "# Flatten labels_encoded using ravel()\n",
    "labels_encoded = prediction.ravel()\n",
    "\n",
    "# Inverse transform one-hot encoded labels\n",
    "labels_encoded_inverse = encoder.inverse_transform(labels_encoded.reshape(-1, 866))\n",
    "labels_encoded_inverse= labels_encoded_inverse.ravel()\n",
    "# Inverse transform label encoding\n",
    "labels_decoded = label_encoder.inverse_transform(labels_encoded_inverse)\n",
    "\n",
    "# Print the decoded label for the first sample\n",
    "print(labels_decoded[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user input\n",
    "user_input = \"Opps, i feel so bad i want to die, i missed my periods  and my whole body is literally nervous and bleeding. I have a terrible migraines and headaches. I can't sleep.  My whole body is shaking and shivering. I feel dizzy sometimes.\"\n",
    "example_text =  preprocess_text(user_input)\n",
    "print(\"Cleaned and tokenized user input: \",example_text)\n",
    "tokenizer.fit_on_texts(example_text)\n",
    "sequence = tokenizer.texts_to_sequences(example_text)\n",
    "feature = keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_len)\n",
    "\n",
    "example_prediction = model.predict(feature)\n",
    "\n",
    "#decode the prediction\n",
    "labels_encoded = example_prediction.reshape( labels_onehot.shape[1],-1)\n",
    "\n",
    "# Inverse transform one-hot encoded labels\n",
    "labels_encoded_inverse = encoder.inverse_transform(labels_encoded)\n",
    "\n",
    "# Inverse transform label encoding\n",
    "labels_decoded = label_encoder.inverse_transform(labels_encoded_inverse)\n",
    "\n",
    "# Print the decoded label for the first sample\n",
    "print(labels_decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2adebdb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 29.8 MiB for an array with shape (866, 4507) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15612\\1802960470.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15612\\1802960470.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(X, Y, hidden_layer_size, num_iterations, learning_rate)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mA2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategorical_cross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15612\\1802960470.py\u001b[0m in \u001b[0;36mforward_propagation\u001b[1;34m(X, parameters)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mZ1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mA1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mZ2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mA2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"Z1\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mZ1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"A1\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Z2\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mZ2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"A2\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 29.8 MiB for an array with shape (866, 4507) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "#input_size = 150, hidden_size= 128, output_size = num_classes=866\n",
    "# initialize weights and biases\n",
    "def init_params(input_size, hidden_size, output_size):\n",
    "    np.random.seed(0)\n",
    "    W1 = np.random.randn(hidden_size, input_size) * 0.01\n",
    "    b1 = np.zeros((hidden_size, 1))\n",
    "    W2 = np.random.randn(output_size, hidden_size) * 0.01\n",
    "    b2 = np.zeros((output_size, 1))\n",
    "    parameters = [W1, b1,  W2, b2]\n",
    "    return parameters\n",
    "\n",
    "parameters= init_params(max_len,128,num_classes)\n",
    "\n",
    "def ReLU(Z,alpha=0.1):\n",
    "    return np.maximum(alpha*Z, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=0))  # Subtract the maximum value\n",
    "    return exp_Z / (np.sum(exp_Z, axis=0)+1e-15)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def categorical_cross_entropy_loss(A2, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    A2 -- probability vector corresponding to the predicted probabilities of a sample belonging to each class, shape (m, num_classes)\n",
    "    Y -- true \"label\" vector, where each value is 0 or 1 for each class, shape (m, num_classes)\n",
    "    Returns:\n",
    "    loss -- the categorical cross-entropy loss\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[0]  # Number of samples\n",
    "    epsilon = 1e-15  # Small value to avoid taking the logarithm of zero\n",
    "\n",
    "    # Clip A to avoid log(0), and clip 1-A to avoid log(1)\n",
    "    A_clipped = np.clip(A2, epsilon, 1 - epsilon)\n",
    "    Y= Y.T\n",
    "    # Compute the loss\n",
    "    loss = -(1 / m) * np.sum(Y * np.log(A_clipped))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    W1, b1, W2, b2 = parameters\n",
    "    Z1 = np.dot(W1, X.T) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    cache = {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n",
    "    return A2, cache\n",
    "\n",
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    m = Y.shape[0]\n",
    "    W1, b1, W2, b2 = parameters\n",
    "    Z1 = cache[\"Z1\"]\n",
    "    A1 = cache[\"A1\"]\n",
    "    Z2 = cache[\"Z2\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    dA2 = (A2 - Y.T)\n",
    "    dZ2 = dA2 * (A2 * (1-A2))\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * (A1 > 0)\n",
    "    dW1 = (1/m) * np.dot(dZ1, X)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    gradients = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    return gradients\n",
    "\n",
    "def update_parameters(parameters, gradients, learning_rate):\n",
    "    W1, b1, W2, b2 = parameters\n",
    "    dW1 = gradients[\"dW1\"]\n",
    "    db1 = gradients[\"db1\"]\n",
    "    dW2 = gradients[\"dW2\"]\n",
    "    db2 = gradients[\"db2\"]\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    parameters = (W1, b1, W2, b2)\n",
    "    return parameters\n",
    "\n",
    "# train the neural network\n",
    "def train(X, Y, hidden_layer_size, num_iterations, learning_rate):\n",
    "    parameters = init_params(X.shape[1], hidden_layer_size, num_classes)\n",
    "    for i in range(num_iterations):\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        loss = categorical_cross_entropy_loss(A2, Y)\n",
    "        gradients = backward_propagation(parameters, cache, X, Y)\n",
    "        parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}: Loss = {loss}\")\n",
    "    return parameters\n",
    "\n",
    "parameters = train(X_train, y_train, hidden_layer_size=128, num_iterations=3500, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "138a7d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted outcome: [ 23 329 374 611 358 165 102 826 223 320]True outcome: [ 23 329 374 611 358 165 848 415 223 320]\n"
     ]
    }
   ],
   "source": [
    "# predict the labels for new data\n",
    "def predict(X, parameters):\n",
    "    A2, _ = forward_propagation(X, parameters)\n",
    "    predictions= A2.T\n",
    "    return predictions\n",
    "\n",
    "predictions = predict(X_test, parameters)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "   \n",
    "    # Convert predicted probabilities to class labels\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Convert true labels from one-hot encoding to class labels\n",
    "    y_true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    correct_predictions = np.sum(y_pred_labels == y_true_labels)\n",
    "    total_samples = y_true.shape[0]\n",
    "    acc = correct_predictions / total_samples\n",
    "    print(f\"predicted outcome: {y_pred_labels[:10]}True outcome: {y_true_labels[:10]}\")\n",
    "    return acc\n",
    "accuracy_pred = accuracy(y_test,predictions)\n",
    "accuracy_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b8a625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1cddaef",
   "metadata": {},
   "source": [
    "# USER INTERPHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d97c7290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rush   , bdsjklx;zs'\n",
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from tkinter import messagebox\n",
    "from tkinter import StringVar, OptionMenu, Text, Entry, Button, Label\n",
    "\n",
    "# Function to handle prediction based on chosen model\n",
    "def predict():\n",
    "    selected_model = model_var.get()\n",
    "    selected_symptoms = [symptom_var.get() for symptom_var in symptom_vars]\n",
    "    typed_symptoms = userinput.get()\n",
    "    \n",
    "    # Perform prediction based on the selected model\n",
    "    if selected_model == \"SVM\":\n",
    "        # Call SVM prediction function\n",
    "        prediction_result = svm_predict(selected_symptoms, typed_symptoms)\n",
    "    elif selected_model == \"FNN\":\n",
    "        # Call FNN prediction function\n",
    "        prediction_result = fnn_predict(selected_symptoms, typed_symptoms)\n",
    "    elif selected_model == \"CNN\":\n",
    "        # Call CNN prediction function\n",
    "        prediction_result = cnn_predict(selected_symptoms, typed_symptoms)\n",
    "    else:\n",
    "        prediction_result = \"Please select a model\"\n",
    "    \n",
    "    # Display prediction result\n",
    "    result_text.delete('1.0', tk.END)  # Clear previous result\n",
    "    result_text.insert(tk.END, prediction_result)\n",
    "\n",
    "# Function to handle prediction using Support Vector Machine (SVM)\n",
    "def svm_predict(symptoms , userinput):\n",
    "    input_symptoms = \" \"\n",
    "    if all(symptom == \"None\" for symptom in symptoms) and userinput == \"None\":\n",
    "        return \"OPPS!!\", \"ENTER  SYMPTOMS PLEASE\"\n",
    "    else:\n",
    "        input_symptoms = \" \".join(symptom for symptom in symptoms if symptom != \"None\")\n",
    "        if userinput != \"None\":\n",
    "            input_symptoms += \", \" + userinput\n",
    "        \n",
    "        print(input_symptoms)\n",
    "        text = preprocess_text(input_symptoms)\n",
    "    \n",
    "        # Tokenize and pad the sequence\n",
    "        sequence = tokenizer.texts_to_sequences([text])\n",
    "        feature = pad_sequences(sequence, maxlen=max_len)\n",
    "\n",
    "        # Make prediction\n",
    "        prediction = model.predict(feature)\n",
    "      \n",
    "        # Flatten labels_encoded using ravel()\n",
    "        labels_encoded = prediction.ravel()\n",
    "\n",
    "        # Inverse transform one-hot encoded labels\n",
    "        labels_encoded_inverse = encoder.inverse_transform(labels_encoded.reshape(-1, 866))\n",
    "        labels_encoded_inverse= labels_encoded_inverse.ravel()\n",
    "        # Inverse transform label encoding\n",
    "        labels_decoded = label_encoder.inverse_transform(labels_encoded_inverse)\n",
    "      \n",
    "        # Display the predicted disease\n",
    "        predicted_disease = labels_decoded[0]\n",
    "        return \"Disease Prediction\", f\"The predicted disease is for symptoms, {input_symptoms} is : {predicted_disease}\"\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# Function to handle prediction using Feedforward Neural Network (FNN)\n",
    "def fnn_predict(symptoms, userinput):\n",
    "    # Code for FNN prediction\n",
    "    return \"Prediction using FNN model\"\n",
    "\n",
    "# Function to handle prediction using Convolutional Neural Network (CNN)\n",
    "def cnn_predict(symptoms, userinput):\n",
    "    # Code for CNN prediction\n",
    "    return \"Prediction using CNN model\"\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Disease Prediction From Symptoms\")\n",
    "\n",
    "# Styling\n",
    "bg_color = \"#f0f0f0\"\n",
    "font_style = (\"Helvetica\", 12)\n",
    "\n",
    "# Main Frame\n",
    "main_frame = tk.Frame(root, bg=bg_color)\n",
    "main_frame.pack(padx=20, pady=20)\n",
    "\n",
    "# Header\n",
    "header_label = tk.Label(main_frame, text=\"Disease Prediction From Symptoms\", font=(\"Helvetica\", 18), bg=bg_color)\n",
    "header_label.grid(row=0, column=0, columnspan=2, pady=10)\n",
    "\n",
    "# Symptoms Section\n",
    "symptoms_label = tk.Label(main_frame, text=\"Choose symptoms or type your symptoms:\", font=font_style, bg=bg_color)\n",
    "symptoms_label.grid(row=1, column=0, columnspan=2, pady=(0, 5))\n",
    "\n",
    "symptoms_options = [\"None\", \"rush\", \" bleeding\", \"Blisters\", \"tired\", \"Symptom 5\", \"Symptom 6\", \"Symptom 7\"]\n",
    "Symptom1 = StringVar()\n",
    "Symptom1.set(None)\n",
    "Symptom2 = StringVar()\n",
    "Symptom2.set(None)\n",
    "Symptom3 = StringVar()\n",
    "Symptom3.set(None)\n",
    "Symptom4 = StringVar()\n",
    "Symptom4.set(None)\n",
    "Symptom5 = StringVar()\n",
    "Symptom5.set(None)\n",
    "Symptom6 = StringVar()\n",
    "Symptom6.set(None)\n",
    "Symptom7 = StringVar()\n",
    "Symptom7.set(None)\n",
    "symptom_vars = [StringVar() for _ in range(7)]\n",
    "for i in range(7):\n",
    "    tk.Label(main_frame, text=f\"Symptom {i+1}:\", font=font_style, bg=bg_color).grid(row=i+2, column=0, pady=5, padx=(0, 10))\n",
    "    OptionMenu(main_frame,symptom_vars[i], *symptoms_options).grid(row=i+2, column=1, pady=5)\n",
    "\n",
    "# userInput\n",
    "tk.Label(main_frame, text=\"Input Symptoms:\", font=font_style, bg=bg_color).grid(row=9, column=0, pady=5, padx=(0, 10))\n",
    "userinput = StringVar()\n",
    "Entry(main_frame, textvariable=userinput).grid(row=9, column=1, pady=5)\n",
    "\n",
    "# Model Selection\n",
    "model_label = tk.Label(main_frame, text=\"Select prediction model:\", font=font_style, bg=bg_color)\n",
    "model_label.grid(row=10, column=0, columnspan=2, pady=(10, 5))\n",
    "\n",
    "model_options = [\"SVM\", \"FNN\", \"CNN\"]\n",
    "model_var = StringVar()\n",
    "model_var.set(model_options[0])  # Set default model\n",
    "OptionMenu(main_frame, model_var,*model_options).grid(row=11, column=0, columnspan=2)\n",
    "\n",
    "# Predict Button\n",
    "predict_button = tk.Button(main_frame, text=\"Predict\", command=predict, bg=\"#4CAF50\", fg=\"white\", font=font_style)\n",
    "predict_button.grid(row=12, column=0, columnspan=2, pady=(10, 0))\n",
    "\n",
    "# Result Section\n",
    "result_label = tk.Label(main_frame, text=\"Prediction Result:\", font=font_style, bg=bg_color)\n",
    "result_label.grid(row=13, column=0, columnspan=2, pady=(20, 5))\n",
    "\n",
    "result_text = Text(main_frame, height=2, width=50)\n",
    "result_text.grid(row=14, column=0, columnspan=2, pady=(0, 10))\n",
    "\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4e7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
